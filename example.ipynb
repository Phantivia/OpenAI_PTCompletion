{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Define Your Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your specific task by defining validate func & postprocess func\n",
    "from ptcompletion import OpenAITask\n",
    "\n",
    "class LlamaPoemTask(OpenAITask):\n",
    "\n",
    "    def validate(self, completion:str):\n",
    "        '''\n",
    "        Check if generated completion fits your intend format.\n",
    "        Return: A bool value.\n",
    "        '''\n",
    "        return completion.startswith('LLAMA!')\n",
    "\n",
    "    def postprocess(self, completion:str):\n",
    "        '''\n",
    "        Postprocess generated completion.\n",
    "        Return: Postprocess result in a pytho dict.\n",
    "        '''\n",
    "        completion = completion.replace('LLAMA!', 'Oh my LLAMA!')\n",
    "        return {'genrated_poem': completion.strip()}\n",
    "\n",
    "# Create context & generation config\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Please write me two lines of poetry about llama. Your response should start with : LLAMA! ..'\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_config = dict(\n",
    "    temperature=1.0,\n",
    "    top_p=1,\n",
    "    n=1, # n>1 is not supported in my default OpenAITask class. Please write your own task class if you want it.\n",
    "    max_tokens = 128,\n",
    ")\n",
    "\n",
    "# OpenAI settings\n",
    "\n",
    "api_key = r'YOUR_OPENAI_API_KEY_HERE'\n",
    "model = 'gpt-3.5-turbo'\n",
    "\n",
    "task = LlamaPoemTask(id=0, messages=messages, generation_config={}, model=model, api_key=api_key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Test Your Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not task.completed:\n",
    "    # Run until the task is completed.\n",
    "    task.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.LlamaPoemTask'>\n",
      "Result: {'genrated_poem': 'Oh my LLAMA! With wool so soft and fine,\\nGraceful and quirky, a wonder divine.'}\n",
      "Completion: LLAMA! With wool so soft and fine,\n",
      "Graceful and quirky, a wonder divine.\n",
      "Input: [{'role': 'user', 'content': 'Please write me two lines of poetry about llama. Your response should start with : LLAMA! ..'}]\n"
     ]
    }
   ],
   "source": [
    "print(task)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run Your Tasks Parallelly with TaskQueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_list = [[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': f'Please write me two lines of poetry about llama and number {i}. Your response should start with : LLAMA! ..'\n",
    "    }\n",
    "] for i in range(10)]\n",
    "\n",
    "tasks = [LlamaPoemTask(id = i,\n",
    "                    messages=messages,\n",
    "                    generation_config=generation_config,\n",
    "                    model=model,\n",
    "                    api_key=api_key)\n",
    "                    for i, messages in enumerate(messages_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptcompletion import TaskQueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://platform.openai.com/docs/guides/rate-limits for RPM limits.\n",
    "\n",
    "tq = TaskQueue(requests_per_minute=60, max_rounds=3, max_requests_per_proc=16, log_file='tasks.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-15 10:04:59.951124] Task 0 Start.\n",
      "[2023-05-15 10:05:00.953344] Task 1 Start.\n",
      "[2023-05-15 10:05:01.955358] Task 2 Start.\n",
      "Query Error:  APIConnectionError(message='Error communicating with OpenAI: (\"Connection broken: InvalidChunkLength(got length b\\'\\', 0 bytes read)\", InvalidChunkLength(got length b\\'\\', 0 bytes read))', http_status=None, request_id=None)\n",
      "[2023-05-15 10:05:02.433979] Task 1 Failed in 1.481 seconds.\n",
      "[2023-05-15 10:05:02.957453] Task 3 Start.\n",
      "[2023-05-15 10:05:03.959630] Task 4 Start.\n",
      "[2023-05-15 10:05:04.961729] Task 5 Start.\n",
      "[2023-05-15 10:05:05.245120] Task 0 Completed in 5.294 seconds.\n",
      "[2023-05-15 10:05:05.477898] Task 2 Completed in 3.523 seconds.\n",
      "[2023-05-15 10:05:05.963858] Task 6 Start.\n",
      "[2023-05-15 10:05:06.106010] Task 3 Completed in 3.149 seconds.\n",
      "[2023-05-15 10:05:06.965758] Task 7 Start.\n",
      "[2023-05-15 10:05:07.069804] Task 4 Completed in 3.11 seconds.\n",
      "[2023-05-15 10:05:07.967709] Task 8 Start.\n",
      "[2023-05-15 10:05:08.021300] Task 5 Completed in 3.06 seconds.\n",
      "[2023-05-15 10:05:08.969854] Task 9 Start.\n",
      "[2023-05-15 10:05:09.076347] Task 6 Completed in 3.112 seconds.\n",
      "[2023-05-15 10:05:10.170584] Task 7 Completed in 3.205 seconds.\n",
      "[2023-05-15 10:05:11.171568] Task 8 Completed in 3.204 seconds.\n",
      "[2023-05-15 10:05:11.840690] Task 9 Completed in 2.871 seconds.\n",
      "[2023-05-15 10:05:11.850251] Round 1 End in 11.962 Seconds. 9 Task Completed. 1 Tasks Failed.\n",
      "[2023-05-15 10:05:12.932515] Task 1 Start.\n",
      "[2023-05-15 10:05:15.940868] Task 1 Completed in 3.008 seconds.\n",
      "[2023-05-15 10:05:15.948016] Round 2 End in 4.097 Seconds. 10 Task Completed. 0 Tasks Failed.\n",
      "[2023-05-15 10:05:15.948286] All 10 Tasks Completed at Round 2, in 16.06 Seconds.\n"
     ]
    }
   ],
   "source": [
    "completed_tasks = tq.start(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK Queue Idx 1, TASK 0\n",
      "{'genrated_poem': 'Oh my LLAMA! Oh, how strange,\\nAs a zero, you pose no range.'}\n",
      "TASK Queue Idx 2, TASK 2\n",
      "{'genrated_poem': \"Oh my LLAMA! With two humps on their back,\\nNumber 2, they're always on track.\"}\n",
      "TASK Queue Idx 3, TASK 3\n",
      "{'genrated_poem': 'Oh my LLAMA! Three toes on each foot,\\nIn fields of green, they stand aloof.'}\n",
      "TASK Queue Idx 4, TASK 4\n",
      "{'genrated_poem': 'Oh my LLAMA! Four legs and fur,  \\nfour times the charm, I concur.'}\n",
      "TASK Queue Idx 5, TASK 5\n",
      "{'genrated_poem': 'Oh my LLAMA! Oh graceful creature so alive,\\nOh how five seems to be your lucky thrive.'}\n",
      "TASK Queue Idx 6, TASK 6\n",
      "{'genrated_poem': 'Oh my LLAMA! With six legs you prance so free,\\nYour oddity brings smiles to me.'}\n",
      "TASK Queue Idx 7, TASK 7\n",
      "{'genrated_poem': 'Oh my LLAMA! Oh your beauty so divine,\\nYour seven layers, I wish were mine.'}\n",
      "TASK Queue Idx 8, TASK 8\n",
      "{'genrated_poem': 'Oh my LLAMA! On the Andean plains so great, \\nEight of them line up, just as fate.'}\n",
      "TASK Queue Idx 9, TASK 9\n",
      "{'genrated_poem': 'Oh my LLAMA! Graceful and divine, \\nNumber nine, your lucky design.'}\n",
      "TASK Queue Idx 10, TASK 1\n",
      "{'genrated_poem': 'Oh my LLAMA! Oh how grand, \\nNumber 1, the king of the land.'}\n"
     ]
    }
   ],
   "source": [
    "for idx, t in enumerate(completed_tasks):\n",
    "    print(f'TASK Queue Idx {idx+1}, TASK {t.id}')\n",
    "    print(t.result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flamingo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
